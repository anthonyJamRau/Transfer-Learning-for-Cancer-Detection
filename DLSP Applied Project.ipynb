{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fecc03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import tiatoolbox\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "#from tiatoolbox.tools import stainnorm\n",
    "from tiatoolbox import data\n",
    "import random\n",
    "import augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eda1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_df = pd.read_csv('/home/meredithc/Transfer-Learning-for-Cancer-Detection/BreakHis/Folds.csv',dtype = {\"mag\":\"string\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f4008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8245b7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_df['class'] = fold_df['filename'].apply(lambda x:x.split(\"/\")[3])\n",
    "fold_df['sub_class'] = fold_df['filename'].apply(lambda x:x.split(\"/\")[5])\n",
    "fold_df['patient_id'] = fold_df['filename'].apply(lambda x:x.split(\"/\")[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1a9d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_df = fold_df[fold_df[\"fold\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0526ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ONCE to copy files into single directory with new image name\n",
    "\n",
    "# destination_folder = \"Input/\"\n",
    "# for row in range(len(fold_df)):\n",
    "#     source_file = \"BreakHis/BreaKHis_v1/\" + fold_df.loc[row,\"filename\"]\n",
    "#     destination_path = os.path.join(destination_folder,fold_df.loc[row,\"mag\"]+\"_\"+\n",
    "#                                                        fold_df.loc[row,\"class\"]+\"_\"+\n",
    "#                                                        fold_df.loc[row,\"sub_class\"]+\"_\"+\n",
    "#                                                        fold_df.loc[row,\"patient_id\"])\n",
    "#     shutil.copy(source_file, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db4a633",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['mag', 'class', 'sub_class','patient_id']\n",
    "fold_df['input_path'] = fold_df[cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dfe4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_df['input_path'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78c2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the patient ID from the image name\n",
    "\n",
    "fold_df = fold_df.rename(columns = {\"patient_id\":\"image_name\"})\n",
    "# fold_df['patient_id'] = fold_df['image_name'].apply(lambda x:[char for char in x.split(\"-\")[2] if char.isnumeric()])\n",
    "# fold_df['patient_id'] = fold_df['patient_id'].apply(lambda x:''.join(x))\n",
    "\n",
    "fold_df['patient_id'] = fold_df['image_name'].apply(lambda x:x.split(\"-\")[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe49613",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_df['encoded_class'] = fold_df['class'].apply(lambda x: 0 if x =='benign' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd9307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.set(font_scale = 1.5)\n",
    "sns.histplot(fold_df['class']);\n",
    "plt.xlabel(\"Class\")\n",
    "plt.title(\"Num Patients Benign and Malignant\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13037a07",
   "metadata": {},
   "source": [
    "malignant = 1 (true class) benign = 0 (false class) The classes are majorly imabalanced. There are some balancing techniques we could employ (downsampling, upsampling, synthetic data augmentation) to enrich the models predictive power in the benign class, but there would be a cost because we intend to maximize the recall metric. In the domain of cancer classification, we should greatly penalize false positives, which means the system did not detect cancer when there really was cancer present. Something to consider is just balancing the data in the train set, but leaving the validation set imbalanced to try and maximize the recall and match real world scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca61f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_df = fold_df[fold_df['class'] == 'benign']\n",
    "malignant_df = fold_df[fold_df['class'] == 'malignant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a38b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30,10))\n",
    "for i in range(0,40):\n",
    "    plt.subplot(4,10,i+1)\n",
    "    img = cv2.imread(\"Input/\"+ benign_df['input_path'][i],1)\n",
    "    plt.imshow(img)\n",
    "plt.title(\"Benign Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea015dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into training, testing, validation sets - making sure that the whole set of images from a particular patient are put into either train or test\n",
    "# 80 train, 10 test, 10 validation\n",
    "splitter = GroupShuffleSplit(test_size=.20, n_splits=2, random_state = 7)\n",
    "split = splitter.split(fold_df, groups=fold_df['patient_id'])\n",
    "train_inds, test_inds = next(split)\n",
    "\n",
    "train = fold_df.iloc[train_inds].reset_index(drop = True)\n",
    "temp_test = fold_df.iloc[test_inds].reset_index(drop = True)\n",
    "\n",
    "splitter_2 = GroupShuffleSplit(test_size=.50, n_splits=2, random_state = 8)\n",
    "split_2 = splitter_2.split(temp_test, groups = temp_test['patient_id'])\n",
    "test_inds, validation_inds = next(split_2)\n",
    "\n",
    "test = temp_test.iloc[test_inds].reset_index(drop = True)\n",
    "validation = temp_test.iloc[validation_inds].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489a318d",
   "metadata": {},
   "source": [
    "### Setting up Stain normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa80b298",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image = data.stain_norm_target()\n",
    "plt.imshow(target_image)\n",
    "plt.axis(\"off\")\n",
    "plt.title('Target Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad973a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can use MacenkoNormalizer, ReinhardNormalizer, RuifrokNormalizer or VahadaneNormalizer\n",
    "normalizer = stainnorm.ReinhardNormalizer()\n",
    "normalizer.fit(target_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae75dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot stain normalized images\n",
    "img = cv2.imread(\"Input/\"+ benign_df['input_path'][1],1)\n",
    "plt.imshow(img)\n",
    "normalized_img = normalizer.transform(img)\n",
    "plt.imshow(normalized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354f6848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_train(image_path: str, dest_path: str, normalizer):\n",
    "    try:\n",
    "        img = cv2.imread('Input/' + image_path)\n",
    "        normalizer.transform(img)\n",
    "        cv2.imwrite(dest_path + image_path, img)\n",
    "    except:\n",
    "        print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_file(image_path: str, dest_path: str):\n",
    "    try:\n",
    "        if 'malignant' in image_path:\n",
    "            dest_path += 'Malignant/'\n",
    "            prefix = 'Normalized/Malignant/'\n",
    "        else:\n",
    "            dest_path += 'Benign/'\n",
    "            prefix = 'Normalized/Benign/'\n",
    "        img = cv2.imread(prefix + image_path)\n",
    "        cv2.imwrite(dest_path + image_path, img)\n",
    "    except:\n",
    "        print(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33dc848",
   "metadata": {},
   "source": [
    "### Augmenting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train))\n",
    "print(len(test))\n",
    "print(len(validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Seperate directories for each class for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_train = train[train['class'] == 'benign']\n",
    "malignant_train = train[train['class'] == 'malignant']\n",
    "benign_test = test[test['class'] == 'benign']\n",
    "malignant_test = test[test['class'] == 'malignant']\n",
    "benign_val = validation[validation['class'] == 'benign']\n",
    "malignant_val = validation[validation['class'] == 'malignant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['input_path'].map(lambda x: copy_file(x, 'Normalized-Train/'))\n",
    "test['input_path'].map(lambda x: copy_file(x, 'Normalized-Test/'))\n",
    "validation['input_path'].map(lambda x: copy_file(x, 'Normalized-Validation/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ec25eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations.augment_images(benign_train['input_path'], 0.5, 'Normalized-Train/Benign/', 'Normalized-Train/Benign/', 3)\n",
    "augmentations.augment_images(malignant_train['input_path'], 0.4, 'Normalized-Train/Malignant/', 'Normalized-Train/Malignant/', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "malignant_df['input_path'].map(lambda x: normalize_train(x, 'Normalized/Malignant/', normalizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d32aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = flip_augmentation('Input/', train['input_path'][0], '', 1.0, False)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90d8a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rotate_augmentation(train['input_path'][0], '', 1.0, False)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e0dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations.augment_images(train['input_path'], 0.87, 'Normalized/', 'Train/Augmented/', 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
